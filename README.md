# ğŸ¢ Internal RBAC Chatbot (Offline RAG System)

A fully offline **Role-Based Access Control (RBAC) AI Assistant** built using:

- ğŸ” FastAPI (JWT Authentication)
- ğŸ—‚ BM25 / TF-IDF Lexical PageIndex (Custom Inverted Index)
- ğŸ§  Vectorless Keyword Search (High Precision, Zero Dep)
- ğŸ¤– Ollama + Phi3 (Local LLM)
- ğŸ“Š Department-Based Access Control
- ğŸ— Clean Modular Backend Architecture

This project simulates a real **enterprise internal knowledge assistant** that restricts document access based on user roles.

---

## ğŸš€ Features

- âœ… JWT-based authentication
- âœ… Role-Based Access Control (RBAC)
- âœ… Department-level document filtering
- âœ… Sub-second lexical similarity search using inverted indexes
- âœ… Fully offline LLM (no API key required)
- âœ… Context-aware RAG pipeline
- âœ… Clean service-based architecture
- âœ… Config-driven environment setup

---

## ğŸ— Architecture Overview

User  
â†“  
FastAPI (JWT Auth)  
â†“  
Role Validation  
â†“  
Lexical PageIndex (Inverted Index Search + Metadata Filter)  
â†“  
Ollama (Local LLM - Phi3)  
â†“  
Context-Aware Answer  

---

## ğŸ“‚ Project Structure

```
Internal-Chatbot-RBAC/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ security.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ index_builder.py
â”‚   â”‚   â”œâ”€â”€ rag_orchestrator.py
â”‚   â”‚   â”œâ”€â”€ retrieval.py
â”‚   â”‚   â”œâ”€â”€ streaming.py
â”‚
â”œâ”€â”€ data/                # Department documents
â”œâ”€â”€ page_index/          # Offline lexical inverted index storage
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ” Roles & Access

| Role        | Access Scope |
|------------|-------------|
| HR         | HR documents |
| Finance    | Finance documents |
| Marketing  | Marketing documents |
| Engineering| Engineering documents |
| Employee   | General documents |
| C-Level    | All departments |

---

## ğŸ§  RAG Workflow

1. User logs in â†’ receives JWT token  
2. User sends query to `/chat`  
3. Role extracted from JWT  
4. TF-IDF retrieval targets optimal content section filtered by department  
5. Retrieved context passed to local LLM  
6. LLM generates answer using ONLY internal context  

---

# âš™ï¸ Installation Guide (Step-by-Step)

This guide is for anyone cloning the repository.

---

## 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/YOUR-USERNAME/Internal-Chatbot-RBAC.git
cd Internal-Chatbot-RBAC
```

---

## 2ï¸âƒ£ Create Virtual Environment

Mac/Linux:

```bash
python -m venv venv
source venv/bin/activate
```

Windows:

```bash
python -m venv venv
venv\Scripts\activate
```

---

## 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

# ğŸ—„ 4ï¸âƒ£ Seed the User Database (VERY IMPORTANT)

Before running the server, you must create initial users.

Run:

```bash
python app/seed.py
```

This will:

- Create SQLite database (`users_database.db`)
- Insert sample users with roles
- Prepare login credentials

---

## ğŸ” Sample Seeded Users

| Username | Password | Role |
|----------|----------|------|
| hr_user | 1234 | hr |
| finance_user | 1234 | finance |
| marketing_user | 1234 | marketing |
| engineering_user | 1234 | engineering |
| nishant | 1234 | c-level |

---

# ğŸ¤– 5ï¸âƒ£ Install Ollama (Required for LLM)

### Mac:

```bash
brew install ollama
```

### Pull Model:

```bash
ollama pull phi3
```

---

# â–¶ 6ï¸âƒ£ Start Ollama Server

```bash
ollama serve
```

Leave this running in background.

---

# ğŸ“š 7ï¸âƒ£ Build Document PageIndex

Run:

```bash
python app/services/index_builder.py
```

This will:

- Read department folders inside `/data`
- Split documents into chunks
- Extract section tokens
- Generate inverted and IDF indices inside `page_index/`

---

# ğŸš€ 8ï¸âƒ£ Run FastAPI Server

```bash
uvicorn main:app --reload
```

Server runs at:

```
http://127.0.0.1:8000
```

---

# ğŸŒ 9ï¸âƒ£ Open API Docs

Open in browser:

```
http://127.0.0.1:8000/docs
```

---

# ğŸ”‘ ğŸ”Ÿ Usage Flow

1. Call `/login`
2. Enter seeded credentials
3. Copy access token
4. Click **Authorize**
5. Paste token
6. Call `/chat`
7. Ask questions based on your role

---

# ğŸ§ª Example Test Queries

### HR User:
```
What is the leave policy?
```

### Finance User:
```
Summarize financial performance over the past three years.
```

### C-Level User:
```
Provide an executive summary of company performance across all departments.
```

---

# ğŸ›  Configuration

All runtime configs are managed via:

```
app/core/config.py
```

Includes:
- Token expiry
- Ollama URL
- Model name
- Collection name

---

# ğŸ§© Tech Stack

| Component | Technology |
|------------|------------|
| Backend | FastAPI |
| Auth | JWT |
| Search Engine | Custom TF-IDF PageIndex |
| Extraction | Regex / NLTK Tokenization |
| LLM | Ollama (Phi3) |
| Chunking | Markdown Section Splitting |

---

# ğŸ† Future Improvements

- Add document citations
- Add chat history memory
- Add streaming response
- Add audit logging
- Add Docker deployment
- Add frontend UI

---

# ğŸ‘¨â€ğŸ’» Author

Nishant  
B.Tech CSE | Backend & AI Systems Enthusiast  

---
